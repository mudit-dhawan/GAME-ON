{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caY4WoB7P2xU",
        "outputId": "a9613af2-7d4e-4207-8583-38ac066a8de0"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5mrvtEbWPcdD"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tilAp5EbP9bL"
      },
      "outputs": [],
      "source": [
        "class MCAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MCAN, self).__init__()\n",
        "\n",
        "        ## Frequency feature extractor\n",
        "        self.conv1 = nn.Conv1d(64, 32, 3)\n",
        "        self.conv2 = nn.Conv1d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv1d(64, 128, 3)\n",
        "        self.conv4 = nn.Conv1d(64, 64, 1)\n",
        "        self.conv5 = nn.Conv1d(64, 48, 1)\n",
        "        self.conv6 = nn.Conv1d(64, 64, 1)\n",
        "        self.conv7 = nn.Conv1d(64, 32, 1)\n",
        "        self.conv8 = nn.Conv1d(48, 64, 3)\n",
        "        self.conv9 = nn.Conv1d(64, 96, 3)\n",
        "        self.conv10 = nn.Conv1d(96, 96, 3)\n",
        "        self.conv11 = nn.Conv1d(64, 64, 1)\n",
        "        \n",
        "        ## Resize different modalities\n",
        "        self.t_fc = nn.Linear(768, 256)\n",
        "\n",
        "        self.s_fc = nn.Linear(1024, 256)\n",
        "\n",
        "        self.f_fc = nn.Linear(122, 256)\n",
        "\n",
        "        ## Co-Attention Block 1\n",
        "        self.ca1 = nn.TransformerEncoderLayer(d_model=256, nhead=4, dim_feedforward=512)\n",
        "        self.ca2 = nn.TransformerEncoderLayer(d_model=256, nhead=4, dim_feedforward=512)\n",
        "\n",
        "        ## Co embed 1\n",
        "        self.co_embed1 = nn.Linear(512, 256)\n",
        "\n",
        "        ## Co-Attention Block 2\n",
        "        self.ca3 = nn.TransformerEncoderLayer(d_model=256, nhead=4, dim_feedforward=512)\n",
        "        self.ca4 = nn.TransformerEncoderLayer(d_model=256, nhead=4, dim_feedforward=512)\n",
        "\n",
        "        ## Co embed 2\n",
        "        self.co_embed2 = nn.Linear(512, 256)\n",
        "\n",
        "        ## Fake news detector\n",
        "        self.p_fc = nn.Linear(256, 35)\n",
        "        self.p2_fc = nn.Linear(35, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MmEhlXxGP9YD"
      },
      "outputs": [],
      "source": [
        "mcan = MCAN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbv-LWtcPcZc",
        "outputId": "135b3111-0a79-456e-e059-9407838af943"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2981211"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(p.numel() for p in mcan.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mQUjGWzE6Hqd"
      },
      "outputs": [],
      "source": [
        "class HMCAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HMCAN, self).__init__()\n",
        "\n",
        "        ## Contextual transformer 1\n",
        "        self.ct1_siglemodal = nn.TransformerEncoderLayer(d_model=768, nhead=1)\n",
        "        self.ct1_multlemodal = nn.TransformerEncoderLayer(d_model=768, nhead=1)\n",
        "\n",
        "        # concat these two to get C_{TI} = 1536 dim\n",
        "\n",
        "        ## Contextual transformer 2\n",
        "        self.ct2_siglemodal = nn.TransformerEncoderLayer(d_model=768, nhead=1)\n",
        "        self.ct2_multlemodal = nn.TransformerEncoderLayer(d_model=768, nhead=1)\n",
        "\n",
        "        # concat these two to get C_{IT} = 1536 dim\n",
        "\n",
        "        ## therefore C_i = \\alpha * C_IT + \\beta * C_TI == 1536 dim  \n",
        "        ## second option assume to be 768 dim because of pooling and post dim\n",
        "\n",
        "        ## Fake news detector\n",
        "        self.fnd = nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GQfrH5IR6Hnl"
      },
      "outputs": [],
      "source": [
        "hmcan = HMCAN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hqseh9A96QX",
        "outputId": "5c815ee6-c326-4500-e09c-993d979094cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22057474"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(p.numel() for p in hmcan.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IBPng_Ho_2NF"
      },
      "outputs": [],
      "source": [
        "class SpotFake(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpotFake, self).__init__()\n",
        "\n",
        "        ## Image feature resize1\n",
        "        self.im1 = nn.Linear(4096, 2742)\n",
        "\n",
        "        ## Image feature resize2\n",
        "        self.im2 = nn.Linear(2742, 32)\n",
        "\n",
        "        ## Text feature resize1\n",
        "        self.t1 = nn.Linear(768, 768)\n",
        "\n",
        "        ## Text feature resize2\n",
        "        self.t2 = nn.Linear(768, 32)\n",
        "\n",
        "        ## multimodal layer after concat\n",
        "        self.mm1 = nn.Linear(64, 35)\n",
        "\n",
        "        ## Fake news detection layer\n",
        "        self.fnd = nn.Linear(35, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qTcNu1oE_2DN"
      },
      "outputs": [],
      "source": [
        "spotfake = SpotFake()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Mgs2aL_4iW",
        "outputId": "a3dad422-37f0-4fa3-f176-890fbc47fd31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11939261"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(p.numel() for p in spotfake.parameters())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ModelSizeBaselines.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
